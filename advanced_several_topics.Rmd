---
author: Deependra Dhakal
fontsize: 12pt
title: Advanced course
date: \today
institute:
  - GAASC, Baitadi
  - Tribhuwan University 
output: 
  binb::iqss:
    keep_tex: true
    slide_level: 2
    includes:
      in_header: iqss_beamer_header.tex
classoption: "aspectratio=169"
bibliography: [./../bibliography/bibliographies.bib]
---

```{r setup, include=FALSE}
library(knitr)
require(tidyverse)
set.seed(453)
# invalidate cache when the package version changes
knitr::opts_chunk$set(tidy = FALSE, echo = FALSE, 
                  message = FALSE, warning = FALSE,
                  out.width = "45%", cache = TRUE)
options(knitr.table.format = "latex")
options(knitr.kable.NA = "", digits = 2)
options(kableExtra.latex.load_packages = FALSE)
source("./../scripts/supply-demand-surplus.R")
source("./../scripts/graphics.R")
# require(extrafont) # requires for graphics.R
# require(extrafontdb)
# extrafont::loadfonts()
# extrafont::font_import()
```

# Introduction

## 


# Production possibility frontier

- A production-possibility frontier shows the maximum number of alternative combinations of goods and services that a society or a farm can produce at a given time when there is full utilization of economic resources and technology.
- Alternative combinations of guns and butter output for a hypothetical economy (guns represent the output of military goods, while butter represents nonmilitary goods and services) is shown in Table \ref{tab:gun-butter-ppf-tab}. 

```{r gun-butter-ppf-tab, echo=FALSE}
pps_less <- readxl::read_xlsx("./../data/concepts_of_economics.xlsx", 
                              sheet = "production_possibility_schedule", col_names = TRUE)

pps_less %>% 
  mutate_if(is.numeric, function(x) {
    kableExtra::cell_spec(x, "latex", bold = T, color = kableExtra::spec_color(x, end = 0.8),
                          font_size = kableExtra::spec_font_size(x))
    }) %>%
  mutate_at("Alternative outputs", function(x) {kableExtra::cell_spec(
    x, "latex", color = "white", bold = T,
    background = kableExtra::spec_color(seq_along(1:nrow(.)), end = 0.9, option = "A", direction = -1)
    )}) %>% 
  knitr::kable(format = "latex", caption = "Production possibility schedule", 
               escape = F, booktabs = T, linesep = "", align = "c") %>% 
  kableExtra::kable_styling(position = "left", full_width = FALSE, font_size = 6) %>% 
  kableExtra::column_spec(1:3, width = "10em")
```

##

- In choosing what to produce, decision makers have a choice of producing, for example, alternative "C" (5,000 guns and 14 million units of butter) or any other alternative presented.
- This production-possibility schedule is plotted and shown in Figure \ref{fig:gun-butter-ppf-fig}. The curve, labeled PP, is called the production-possibility frontier. 

```{r gun-butter-ppf-fig, fig.cap="Production possibility frontier of gun versus butter", fig.width=6, fig.height=4, out.width="60%", echo=FALSE}

pps_less_curve <- as_tibble(Hmisc::bezier(pps_less$`Guns (thousand units)`, y = pps_less$`Butter (million units)`)) %>% 
  magrittr::set_colnames(c("guns_thousands", "butter_millions"))

pps_less_curve %>% 
  ggplot(mapping = aes(x = guns_thousands, y = butter_millions)) +
  geom_path(color = "blue") + 
  geom_label(data = pps_less, aes(x = `Guns (thousand units)`, y = `Butter (million units)`, label = `Alternative outputs`)) +
  theme_bw()
```


## Marginal cost

- The additional cost of doing a little bit more (or 1 unit more if a unit can be measured) of an activity.
- How do you make a rational decision about when the alarm should go off? What you have to do is to weigh up the costs and benefits of additional sleep. Each extra minute in bed gives you more sleep (the marginal benefit), but gives you more of a rush when you get up (the marginal cost).
- The decision is therefore based on the costs and benefits of extra sleep, not on the total costs and benefits of a whole nightâ€™s sleep.

#### Rational decision
- Doing more of an activity if its marginal benefit exceeds its marginal cost and doing less if its marginal cost exceeds its marginal benefit.
- Rational decisions are made with rational choices; that involve weighing up the benefit of any activity against its opportunity cost.

# Indifference curve

## Meaning

- Indifference curve approach is an effort to understanding consumer behavior considering the properties of consumer preferences. The major assumptions associated with the study of consumer behavior include:
  1. Preferences for goods and services are complete
  2. Consumers are consistent
  3. Nonsatiation: More is preferred to less

- Each indifference curve is a set of points, each representing a combination of quantities of two goods or services, all of which combinations the consumer is equally satisfied with. The further a curve is from the origin, the greater is the level of utility.

##

- Indifference curves represent the *theoretical* tradeoff of two goods and your individual preferences. Each curve shows the combination of goods that produce the same level of utility.

- The slope of this line is known as the **marginal rate of substitution (MRS)**(the negative of the marginal rate of substitution of X for Y). The MRS for an individual is the willingness to trade off good X against good Y at any point (maintaining the same level of utility). The curve is convex to the origin as shown assuming the consumer has a **diminishing marginal rate of substitution**. It can be shown that consumer analysis with indifference curves (an ordinal approach) gives the same results as that based on cardinal utility theory - i.e., consumers will consume at the point where the marginal rate of substitution between any two goods equals the ratio of the prices of those goods (the equi-marginal principle)

##

- It can be shown as a lot of other things:
    
$$
MRS = \frac{dy}{dx} = \frac{\Delta y}{\Delta x} = \frac{\text{Price}_x}{\text{Price}_y} = \frac{MU_x}{MU_y} = \frac{\partial u / \partial x}{\partial u / \partial y}
$$

We can find the optimum combination of goods (workers and planes, hours and grades, etc.) by combining the feasible set with indifference curves.

#### Properties
1. Downward sloping: Relates to "More is preferred to less"
2. Everywhere dense: Infinite number of isoquants
3. Cannot intersect
4. Convex to origin: Due to law of diminishing marginal utility

##

- Economists assume that consumers maximize their own utility, subject to a budget constraint. Advertising aims explicitly at changing consumer preferences. Political rhetoric works the same way, and ever-present peer pressure causes consumers to make frequent changes in the pattern of their purchases.

- Production economics tries to answer what happens when the relative prices of consumer goods (food, clothing, books, vacuum cleaners, entertainment, etc.) change. When this occurs, consumers shift their purchases into the less expensive goods and away from the more expensive goods. Indifference curves help show this movement between goods.

##

- A graph of indifference curves for several utility levels of an individual consumer is called an **indifference map**. Points yielding different utility levels are each associated with distinct indifference curves and these indifference curves on the indifference map are like contour lines on a topographical map. Each point on the curve represents the same elevation. If you move "off" an indifference curve traveling in a northeast direction (assuming positive marginal utility for the goods) you are essentially climbing a mound of utility. The higher you go the greater the level of utility. The non-satiation requirement means that you will never reach the "top," or a "bliss point," a consumption bundle that is preferred to all others.

##

```{r indifference-map, fig.width=6, fig.height=4, fig.cap="Indifference curves", echo=FALSE, eval=TRUE, out.width="60%"}
u_xy <- function(x, U) (1*U) / x

ggplot() +
  stat_function(data = tibble(x = 0:20), aes(x = x), fun = u_xy,
                color = "red", size = 1, args = list(U = 40)) +
  annotate(geom = "label", x = 5, y = u_xy(5, 40), label = "U = 40",
           color = "red", size = 4.5) +
  stat_function(data = tibble(x = 0:20), aes(x = x), fun = u_xy,
                color = "blue", size = 1, args = list(U = 20)) +
  annotate(geom = "label", x = 5, y = u_xy(5, 20), label = "U = 20",
           color = "blue", size = 4.5) +
  stat_function(data = tibble(x = 0:20), aes(x = x), fun = u_xy,
                color = "aquamarine", size = 1, args = list(U = 10)) +
  annotate(geom = "label", x = 5, y = u_xy(5, 10), label = "U = 10",
           color = "aquamarine", size = 4.5) +
  stat_function(data = tibble(x = 0:20), aes(x = x), fun = u_xy,
                color = "wheat4", size = 1, args = list(U = 5)) +
  annotate(geom = "label", x = 5, y = u_xy(5, 5), label = "U = 5",
           color = "wheat4", size = 4.5) +
  stat_function(data = tibble(x = 0:20), aes(x = x), fun = u_xy,
                color = "turquoise", size = 1, args = list(U = 12)) +
  annotate(geom = "label", x = 5, y = u_xy(5, 12), label = "U = 12",
           color = "turquoise", size = 4.5) +
  scale_x_continuous(expand = c(0, 0), breaks = seq(0, 22, 5)) + 
  scale_y_continuous(expand = c(0, 0), breaks = seq(0, 20, 4)) +
  coord_cartesian(xlim = c(0, 22), ylim = c(0, 24)) +
  labs(x = "Commodity X", y = "Commodity Y") +
  # theme_econ(14, axis_line = TRUE)
  theme_bw()

```

## Applications

- Consumer theory uses indifference curves and budget constraints to generate consumer demand curves. For a single consumer, this is a relatively simple process. First, let one good be an example market e.g., carrots, and let the other be a composite of all other goods. 
- Budget constraints give a straight line on the indifference map showing all the possible distributions between the two goods; the point of maximum utility is then the point at which an indifference curve is tangent to the budget line. 
- This follows from common sense: if the market values a good more than the household, the household will sell it; if the market values a good less than the household, the household will buy it. 

##

- The process then continues until the market's and household's marginal rates of substitution are equal. Now, if the price of carrots were to change, and the price of all other goods were to remain constant, the gradient of the budget line would also change, leading to a different point of tangency and a different quantity demanded. These price / quantity combinations can then be used to deduce a full demand curve. 
- A line connecting all points of tangency between the indifference curve and the budget constraint is called the expansion path.

## Indifference curve: Construction

> Imagine that waffles (x) cost \$1 and calzones (y) cost \$2. You have a food budget of \$20. Your utility function for waffles and calzones is $u = xy$.

## Figure out the feasible set and the MRT

In this case our feasible set is not a production functionâ€”we aren't limited by workers or time. Instead, we're limited by our budget. We can only spend \$20. If we spend all our money on calzones, we could buy 10 of them. If we spend all our money on waffles, we can buy 20 of them. We can plot all the combinations of waffles and calzones as a *budget line*:

```{r budget-line, echo=FALSE, fig.width=5, fig.height=3, fig.cap="Budget line for a combination of goods.", echo=FALSE, eval=TRUE, out.width="50%", fig.align='center'}
budget <- function(x) (-0.5 * x) + 10

ggplot() +
  stat_function(data = tibble(x = 0:20), aes(x = x), fun = budget,
                color = nord_yellow, size = 2) +
  annotate(geom = "label", x = 2.5, y = budget(2.5), label = "Budget line",
           color = nord_yellow, size = 4.5) +
  scale_x_continuous(expand = c(0, 0), breaks = seq(0, 25, 5)) + 
  scale_y_continuous(expand = c(0, 0), breaks = seq(0, 10, 2)) +
  coord_cartesian(xlim = c(0, 21), ylim = c(0, 11)) +
  labs(x = "Waffles", y = "Calzones") +
  # theme_econ(14, axis_line = TRUE)
  theme_bw()
```

##

We can write this budget line as an equation following the $y = mx + b$ format, where $m$ is the slope and $b$ is the y-intercept. The slope here is the marginal rate of transformation (MRT).

$$
y = -\frac{1}{2} x + 10
$$

## Figure out indifference curves and the MRS

- We can afford every combination of waffles and calzones along the budget line, but we don't know what the optimal mix of waffles and calzones isâ€”that depends on how much we like the two foods, or our *preferences*.
- Our utility function is $u = xy$, which means that we multiply the quantity of waffles and calzones together to get our utility. That is, if we eat 10 waffles and 4 calzones, we'll get 40 utils; if we eat 5 waffles and 14 calzones, we'll get 70 utils; and so on.
- Indifference curves show all the combinations of two goods that provide the same utility. If we want to get 40 utils, we could eat 20 waffles and 2 calzones, 10 waffles and 4 calzones, 5 waffles and 8 calzones, etc. Each of those combinations provides 40 utils of happiness.
- We can calculate the combinations of waffles and calzones that lead to any amount of utility. In the chart below, I show three different indifference curves. Every point along the curve represents the combination of waffles and calzones that would lead to 10, 20, and 40 utils.

##

```{r indifference-curves, echo=FALSE, fig.width=6, fig.height=4, fig.cap="Indifference curves for different utility levels for two commodities.", echo=FALSE, eval=TRUE, out.width="65%", fig.align='center'}
u_xy <- function(x, U) U / x

ggplot() +
  stat_function(data = tibble(x = 0:20), aes(x = x), fun = u_xy,
                color = nord_red, size = 1, args = list(U = 40)) +
  annotate(geom = "label", x = 5, y = u_xy(5, 40), label = "U = 40",
           color = nord_red, size = 4.5) +
  stat_function(data = tibble(x = 0:20), aes(x = x), fun = u_xy,
                color = nord_dk_blue, size = 1, args = list(U = 20)) +
  annotate(geom = "label", x = 5, y = u_xy(5, 20), label = "U = 20",
           color = nord_dk_blue, size = 4.5) +
  stat_function(data = tibble(x = 0:20), aes(x = x), fun = u_xy,
                color = nord_lt_blue, size = 1, args = list(U = 10)) +
  annotate(geom = "label", x = 5, y = u_xy(5, 10), label = "U = 10",
           color = nord_lt_blue, size = 4.5) +
  scale_x_continuous(expand = c(0, 0), breaks = seq(0, 25, 5)) + 
  scale_y_continuous(expand = c(0, 0), breaks = seq(0, 10, 2)) +
  coord_cartesian(xlim = c(0, 21), ylim = c(0, 11)) +
  labs(x = "Waffles", y = "Calzones") +
  # theme_econ(14, axis_line = TRUE)
  theme_bw()
```

##

- Next, we can use this utility function to calculate the *marginal rate of substitution* or MRS, which is the slope of the curve at any given point. In calculus land, we find the slope of a function by calculating the first derivative. For easier one-variable functions like $x^2$, this involves moving the exponent down, multiplying it by the coefficient, and reducing the exponent by one. The first derivative of $x^2$ is $2x$. The derivative of $2x^3$ would be $6x^2$, and so on.
- When differentiating a two-variable function like $xy$, though, we can't just follow the simple rule of moving an exponent down and subtracting one. Instead, we have to calculate partial derivativesâ€”we find the derivative of just the $x$ part while holding $y$ constant and divide it by the derivative of just the $y$ part while holding $x$ constant.
- In this case, where $u = xy$, the slope / first derivative / MRS is $\frac{y}{x}$.

##

- Next, we can add actual numbers to this MRS by setting it equal to the ratio of the prices of waffles and calzones (remember from that big list of things that MRS is, from up above, that MRS also is $\frac{\text{Price}_x}{\text{Price}_y}$):

$$
\frac{y}{x} = \frac{1}{2}
$$

- We can use algebra to rearrange this formula so that it's based on $y$:

$$
y = \frac{1}{2} x
$$

- That is our MRS given the prices that exist in the world. Phew.

## Set MRS = MRT and solve for x and y

- Now that we have formulas for the MRT and the MRS, we can set them equal to each other to find where they are tangent to each other (i.e where their slopes are the same). Algebra time!

$$
\begin{aligned}
MRS &= MRT \\
\frac{1}{2} x &= -\frac{1}{2} x + 10 \\
x &= 10
\end{aligned}
$$

##

- The optimal level of waffles is thus 10. We can plug that back into either the MRS or the MRT equation to figure out the optimal level of calzones:

$$
\begin{aligned}
y &= -\frac{1}{2} x + 10 \\
y &= (-\frac{1}{2} \times 10) + 10 \\
y &= 5
\end{aligned}
$$

- 5 calzones! The best combination food that maximizes our utility given our budget constraint and current prices is **10 waffles and 5 calzones**.
- We can use our utility function to calculate how many utils we get from that level of consumption: $u = xy$, or 10 Ã— 5, or 50.

##

- We can verify this combination graphically by plotting the budget line and indifference curve for 50 utils all at the same time:

```{r all-together, echo=FALSE, fig.width=5, fig.height=3, fig.cap="Indifference curves", echo=FALSE, eval=TRUE, out.width="55%", fig.align='center'}
ggplot() +
  stat_function(data = tibble(x = 0:20), aes(x = x), fun = budget,
                color = nord_yellow, size = 2) +
  annotate(geom = "label", x = 2.5, y = budget(2.5), label = "Budget line",
           color = nord_yellow, size = 4.5) +
  stat_function(data = tibble(x = 0:20), aes(x = x), fun = u_xy,
                color = nord_red, size = 1, args = list(U = 50)) +
  annotate(geom = "label", x = 5, y = u_xy(5, 50), label = "U = 50",
           color = nord_red, size = 4.5) +
  annotate(geom = "point", x = 10, y = 5, size = 3, color = nord_dk_blue) +
  annotate(geom = "label", x = 11, y = 5, label = "Optimal combination",
           size = 4.5, hjust = 0, color = nord_dk_blue
           # family = "Roboto Condensed Bold"
           ) +
  scale_x_continuous(expand = c(0, 0), breaks = seq(0, 25, 5)) + 
  scale_y_continuous(expand = c(0, 0), breaks = seq(0, 10, 2)) +
  coord_cartesian(xlim = c(0, 21), ylim = c(0, 11)) +
  labs(x = "Waffles", y = "Calzones") +
  # theme_econ(14, axis_line = TRUE)
  theme_bw()
```


``` {r}
# Download this from https://github.com/andrewheiss/econw18.classes.andrewheiss.com/blob/master/lib/graphics.R
source("./scripts/graphics.R")

# Create functions
budget <- function(x) 50 - (2 * x)
budget_new <- function(x) 50 - x
budget_shifted <- function(x) 35.5 - x
utility <- function(x, good_x, good_y, adj = 0) sqrt(good_x * good_y)^2 / x + adj

# Annotations for the plot
# It'd be better to figure these out mathematically using the functions, but Â¯\_(ãƒ„)_/Â¯
points_to_show <- tribble(
  ~x,   ~y,  ~label,
  12.5, 25,  "A",
  22,   28,  "B",
  17.5, 18,  "C"
)

effects <- tibble(x_start = c(filter(points_to_show, label == "A") %>% pull(x),
                                  filter(points_to_show, label == "C") %>% pull(x),
                                  filter(points_to_show, label == "A") %>% pull(x)),
                      x_end = c(filter(points_to_show, label == "C") %>% pull(x),
                                filter(points_to_show, label == "B") %>% pull(x),
                                filter(points_to_show, label == "B") %>% pull(x)),
                      label = c("SE", "IE", "TE"),
                      y = c(12, 8, 4))

# Plot everything
ggplot(data = points_to_show, aes(x = x, y = y)) +
  stat_function(data = tibble(x = 0:60), inherit.aes = FALSE,
                aes(x = x, color = "Original budget", size = "Original budget"), 
                fun = budget) +
  stat_function(data = tibble(x = 0:25), inherit.aes = FALSE,
                aes(x = x, color = "New budget", size = "New budget"),
                fun = budget_new) +
  stat_function(data = tibble(x = 0:25), inherit.aes = FALSE,
                aes(x = x), color = "grey70", linetype = "dashed",
                size = 0.5, fun = budget_shifted) +
  stat_function(data = tibble(x = 1:25), inherit.aes = FALSE,
                aes(x = x, color = "Original indifference", size = "Original indifference"), 
                fun = utility, args = list(good_x = 12.5, good_y = 25)) +
  stat_function(data = tibble(x = 1:25), inherit.aes = FALSE,
                aes(x = x, color = "New indifference", size = "New indifference"),
                fun = utility, args = list(good_x = 15.5, good_y = 30, adj = 7)) +
  geom_segment(aes(xend = x, yend = 0), 
               size = 1, color = nord_yellow, linetype = "dotted") +
  geom_point(size = 2) + 
  geom_text(aes(label = label), hjust = "left", nudge_x = 1, size = 6) +
  geom_segment(data = effects, aes(x = x_start, xend = x_end, y = y, yend = y)) +
  geom_text(data = effects, aes(x = (x_start + x_end) / 2, y = y, label = label),
            vjust = 1.3) +
  scale_x_continuous(expand = c(0, 0)) + 
  scale_y_continuous(expand = c(0, 0)) +
  scale_color_manual(values = c("Original budget" = nord_green, 
                                "New budget" = nord_orange, 
                                "Original indifference" = nord_dk_blue, 
                                "New indifference" = nord_lt_blue), 
                     guide = guide_legend(reverse = TRUE), name = NULL) +
  scale_size_manual(values = c("Original budget" = 2.5, 
                               "New budget" = 2.5, 
                               "Original indifference" = 1, 
                               "New indifference" = 1), 
                    guide = guide_legend(reverse = TRUE), name = NULL) +
  coord_equal(xlim = c(0, 50), ylim = c(0, 50)) +
  labs(x = "Good X", y = "Good Y") +
  theme_econ(axis_line = TRUE) +
  theme(panel.grid = element_blank(),
        legend.position = "bottom")
```


# Demand and supply

## 

Let us consider that blackgram (average quality) has the following demand schedule:

```{r}
tribble(~"quantity", ~"price", ~"total_revenue", ~"total_cost", ~"profit", 
        )
```


## Excess demand and supply

Excess demand is the function describing the amount of quantity demanded above quantity supplied at each price level. Mathematically, it is allowed to be negative (so then we have excess quantity supplied actually).
 
Remember that the Walrasian construct imagines an "auction" situation when transactions do not take place as long as the market doesn't clear. So somebody (the "walrasian auctioneer") "announces a price, and buyers declare their desired quantities at that price and sellers declare the quantities they want to sell at that price. If the sum of quantities demanded exceeds the sum of quantities supplied, the excess demand function is strictly positive at that price.

A classic case of real-world strictly positive excess quantity demanded is a very large discount a shop may give for an item, but having decided a priori the pieces it will sell at that prices (the desired quantity supplied at the price). The price may be so low that customers may demand more than the quantities that the store desires to sell at that price.

### Supply function

Let us consider the following linear supply function:

\begin{equation}
\begin{split}
q^s(p^s) = a + bp^s; a < 0, b > 0
\end{split}
\label{eq:supply-func}
\end{equation}

Where,

$q^s(.)$ -- supply function

$q^s$ -- quantity supplied

$p^s$ -- supply price

Parameter $a$ describes the hypothetical quantity of supply for a supply price of zero.
Parameter $b$ describes the slope of the supply function and indicates the change in units supplied as a consequence of an increase of the supply price by one unit.

Inverse function with price on y-axis and quanity on x-axis is given by following inverse supply function. Inverse function is derived by solving Equation \ref{eq:supply-func} with respect to $p^s$.

\begin{equation}
\usetagform{inverseeqn}
\begin{split}
\tilde{p}^s(q^s) = -\frac{a}{b} + \frac{1}{b}q^s
\end{split}
\label{inverse-supply-func}
\end{equation}

Where,

$\tilde{p}^s(.)$ -- inverse supply function 


### Demand function

Let us consider the following linear demand function:

\begin{equation}
\begin{split}
q^d(p^d) = c + dp^d; c > 0, d < 0
\end{split}
\label{demand-func}
\end{equation}

Where,

$q^d(.)$ -- demand function

$q^d$ -- quantity demanded

$p^d$ -- demand price

$c$ -- hypothetical quantity of supply for a supply price of zero.

$d$ -- slope of the supply function that indicates the change in units supplied as a consequence of an increase of the supply price by one unit.

Inverse function with price on y-axis and quanity on x-axis is given by following inverse supply function. Inverse function is derived by solving Equation \ref{eq:demand-func} with respect to $p^d$.

\begin{equation}
\usetagform{inverseeqn}
\begin{split}
\tilde{p}^d(q^d) = -\frac{c}{d} + \frac{1}{d}q^d
\end{split}
\label{inverse-demand-func}
\end{equation}

Where,

$\tilde{p}^d(.)$ -- inverse demand function 

\textbf{\Large Numerical examples on supply demand functions}

Let us consider we have given parameters, a, b, c and d, we can then compute quantity distributions for given price levels with supply and demand functions respectively.

```{r supply-demand-func, eval=FALSE}
# quantity as function of price
s_fun <- function(ps)a + b*ps
d_fun <- function(pd)c + d*pd

a <- -2
b <- 3
c <- 3
d <- -5

s_fun(c(2, 3, 4, 5))
d_fun(c(2, 3, 4, 5))

# price as function of demand

s_fun_inv <- function(qs)-a/b + 1/b*qs
d_fun_inv <- function(qd)-c/d + 1/d*qd

s_fun_inv(c(2, 3, 4, 5))
d_fun_inv(c(2, 3, 4, 5))
```

To solve for equilibrium price and quantity, however, we can algebrically solve the following linear function indicated in the matrix form as follow:

\[
\underbrace{\begin{bmatrix} p^s \\ p^d \end{bmatrix}}_y  = \underbrace{\begin{bmatrix}  a &  b \\ c &  d \end{bmatrix}}_X
  \underbrace{\begin{bmatrix} q^s(p^s) \\ q^d(p^d) \end{bmatrix}}_\beta
\]

## Demand shift

```{r demand-shift}
supply <- Hmisc::bezier(c(1, 8, 9),
                        c(1, 5, 9)) %>%
  data.frame()

demand <- Hmisc::bezier(c(1, 3, 9),
                        c(9, 3, 1)) %>%
  as_tibble()

demand1 <- Hmisc::bezier(c(1, 3, 9),
                        c(9, 3, 1)) %>%
  as_tibble()

demand2 <- Hmisc::bezier(c(3, 5, 11),
                         c(11, 5, 3)) %>%
  data.frame()

# Calculate the intersections of the two curves
intersections <- bind_rows(curve_intersect(supply, demand1),
                           curve_intersect(supply, demand2))

plot_labels <- data_frame(label = c("S", "D[1]", "D[2]"),
                          x = c(8, 1, 5),
                          y = c(8, 8, 8))

ggplot(mapping = aes(x = x, y = y)) + 
  geom_path(data = supply, color = "#0073D9", size = 1) + 
  geom_path(data = demand, color = "#FF4036", size = 1, linetype = "dashed") + 
  geom_path(data = demand2, color = "#FF4036", size = 1) + 
  geom_segment(data = intersections, 
               aes(x = x, y = 0, xend = x, yend = y), lty = "dotted") +
  geom_segment(data = intersections, 
               aes(x = 0, y = y, xend = x, yend = y), lty = "dotted") + 
  geom_text(data = plot_labels,
            aes(x = x, y = y, label = label), parse = TRUE) +
  annotate("segment", x = 3.5, xend = 4.5, y = 6, yend = 7,
           arrow = arrow(length = unit(1, "lines")), colour = "grey50") +
  geom_point(data = intersections, size = 3) +
  scale_x_continuous(expand = c(0, 0), breaks = intersections$x,
                     labels = expression(Q[1], Q[2])) +
  scale_y_continuous(expand = c(0, 0), breaks = intersections$y,
                     labels = expression(P[1], P[2])) +
  labs(x = "Quantity", y = "Price",
       title = "Rightward shift in demand",
       subtitle = "As demand increases, so does price") +
  coord_equal() +
  theme_classic() + 
  theme(plot.title = element_text(size = rel(1.3)))
```


# Demand models

In this section, three different types of demand models for homogeneous products will be compared and how to find optimal prices for each one of them.

For the linear model, demand is given by:

$$\displaystyle d(p) = \alpha p + \beta,$$

where $\alpha$ is the slope of the curve and $\beta$ the intercept. For the linear model, the elasticity goes from zero to infinity. Another very common demand model is the constant-elasticity model, given by:

$$\displaystyle \ln d(p) = \alpha \ln p + \beta,$$

or

$$\displaystyle d(p) = d_0 e^\beta p^\alpha = Cp^\alpha,$$

where $\alpha$ is the elasticity of the demand and C is a scale factor. A much more interesting demand curve is given by the logistic/sigmoide function:

$$\displaystyle d(p) = C\frac{e^{\alpha p + \beta}}{1 + e^{\alpha p + \beta}} = \frac{C}{1+e^{-\alpha(p - p_0)}},$$

where $\displaystyle C$ is a scale factor and $\alpha$ measures price sensitivity. We also can observe $p_0 = -\alpha/\beta$ as the inflection point of the demand.

Some books changes the signs of the coefficients using the assumption that $\alpha$ is a positive constant and using a minus sign in front of it. However, it does not change the estimation procedure or final result, it is just a matter of convenience. Here, we expect $\alpha$ to be negative in the three models.

In the Figure below we can check a comparison among the shapes of the demand models:

```{r shapes-of-demand}
library(reshape2)
library(magrittr)
 
linear = function(p, alpha, beta) alpha*p + beta
constant_elast = function(p, alpha, beta) exp(alpha*log(p)+beta)
logistic = function(p, c, alpha, p0) c/(1+exp(-alpha*(p-p0)))
 
p = seq(1, 100)
y1 = linear(p, -1, 100)
y2 = constant_elast(p, -.5, 4.5)
y3 = logistic(p, 100, -.2, 50)
 
df = data.frame('Prices' = p, 'Linear' = y1, 'Constant_elast' = y2, 'Logistic' = y3)
df.plot = melt(df, id = 'Prices') %>% magrittr::set_colnames(c('Prices', 'Model', 'Demand'))
 
ggplot(df.plot) + aes(x = Prices, y = Demand) +
  geom_line(color = 'blue', alpha = .6, lwd = 1) +
  facet_grid(~Model)
```

Of course that in practice prices does not change between 1 and 100, but the idea is to show the main differences in the shape of the models.

All the models presented above have positive and negative points. Although local linear approximation may be reasonable for small changes in prices, sometimes this assumption is too strong and does not capture the correct sensitivity of bigger price changes. In the constant elasticity model, even though it is a non-linear relationship between demand and price, the constant elasticity assumption might be too restrictive. Moreover, it tends to over estimate the demand for lower and bigger prices. In a fist moment, I would venture to say that the logistic function is the most robust and realistic among the three types.

## Pricing with demand models

In a general setting, one have for the total profit function:

$\displaystyle L(p) = d(p)(p-c),$

where, L gives the profit, d is the demand function that depends of the price and c is the marginal cost. Taking the derivative with respect to price we have:

$\displaystyle L'(p) = d'(p)(p - c) + d(p).$

Making L'(p) = 0 to calculate the optimum price (first order condition), we have:

$$\displaystyle d'(p^\star)(p^\star - c) + d(p^\star) = 0
\displaystyle d'(p^\star)p^\star + d(p^\star) = d'(p^\star)c,$$

which is the famous condition that in the optimal price, marginal cost equals marginal revenue. Next, letâ€™s see how to calculate the optimum prices for each demand functions.

## Linear model

For the linear model $d'(p) = \alpha$. Hence:

$$
\begin{aligned}
\displaystyle d'(p^\star)p + d(p^\star) &= d'(p^\star)c, \\
\displaystyle \alpha p^\star + \alpha p^\star + \beta &= \alpha c, \\
\displaystyle p^\star &= \frac{\alpha c - \beta}{2\alpha}.
\end{aligned}
$$

Example:

```{r example-fit-viz}
# Synthetic data
p = seq(80,130)
d = linear(p, alpha = -1.5, beta = 200) + rnorm(sd = 5, length(p))
c = 75
profit = d*(p-c)
 
# Fit of the demand model
model1 = lm(d~p)
profit.fitted = model1$fitted.values*(p - c)
 
# Pricing Optimization
alpha = model1$coefficients[2]
beta = model1$coefficients[1]
p.max.profit = (alpha*c - beta)/(2*alpha)
 
# Plots
df.linear = data.frame('Prices' = p, 'Demand' = d,
                       'Profit.fitted' = profit.fitted, 'Profit' = profit)
 
ggplot(select(df.linear, Prices, Demand)) + 
  aes(x = Prices, y = Demand) +
  geom_point() + 
  geom_smooth(method = lm)

# plot another
ggplot(select(df.linear, Prices, Profit)) + 
  aes(x = Prices, y = Profit) +
  geom_point() + 
  geom_vline(xintercept = p.max.profit, lty = 2) +
  geom_line(data = df.linear, 
            aes(x = Prices, y = Profit.fitted), color = 'blue')
```

## Constant elasticity model

For the constant elasticity model, since $\lim_{\Delta \rightarrow 0}\frac{\Delta D}{\Delta p} = d'(p)$, we have that:

$$
\displaystyle \epsilon = \frac{\%D}{\%p} = \frac{p\Delta D}{D\Delta p} = -\frac{d'(p)p}{D}.
$$

Therefore,

$$
\begin{aligned}
\displaystyle d'(p^\star)p^\star + d(p^\star) &= d'(p^\star)c, \\
\displaystyle \frac{d'(p^\star)p^\star}{d(p^\star)} + 1 &= \frac{d'(p^\star)c}{d(p^\star)}, \\
\displaystyle -\epsilon + 1 &= \epsilon \frac{c}{p^\star}, \\
\displaystyle p^\star &= \frac{\epsilon c}{1-\epsilon} \\
&= \frac{c}{1-1/\epsilon}.
\end{aligned}
$$

Moreover, knowing that $\frac{\%D}{\%p} \sim \frac{\Delta \ln D}{\Delta \ln p}$ and using the constant elasticity model, we have that:

$$
\displaystyle \epsilon \sim \lim_{\Delta \rightarrow0} \frac{\Delta \ln D}{\Delta \ln P} = \frac{d\ln D}{d\ln p} = \alpha.
$$

Thus, we can calculate the optimum profit price for the constant elasticity model as:

$$\displaystyle p^\star = \frac{c}{1 - \frac{1}{|\alpha|}}$$

It is interesting to note that one needs $|\alpha| > 1$, otherwise the profit function will be convex with respect to price and the optimal price will be $\infty$. If one have a monopolistic market, normally this assumption holds.

Example:

```{r constant-elasticity}
# Synthetic data
p = seq(80,130)
d = constant_elast(p, alpha = -3, beta = 15)*exp(rnorm(sd = .15, length(p)))
c = 75
profit = d*(p-c)
 
# Fitting of demand model
model2 = lm(log(d)~log(p))
profit.fitted = exp(model2$fitted.values)*(p - c)
 
# pricing optimization
alpha = model2$coefficients[2]
p.max.profit = c/(1-1/abs(alpha))
 
# Plots
df.const_elast = data.frame('Prices' = p, 'Demand' = d,
                       'Profit.fitted' = profit.fitted, 'Profit' = profit)
 
ggplot(select(df.const_elast, Prices, Demand)) + aes(x = log(Prices), y = log(Demand)) +
  geom_point() + geom_smooth(method = lm)

ggplot(select(df.const_elast, Prices, Profit)) + 
  aes(x = Prices, y = Profit) +
  geom_point() + 
  geom_vline(xintercept = p.max.profit, lty = 2) +
  geom_line(data = df.const_elast, aes(x = Prices, y = Profit.fitted), color = 'blue')
```

## Logistic model

For the logistic function, one can check that $d'(p) = \alpha d(p)(1-d(p)/C)$. Thus:

$$
\begin{aligned}
\displaystyle d'(p^\star)(p^\star - c) + d(p^\star) &= 0, \\
\displaystyle \alpha d(p^\star)(1-d(p^\star)/C)(p^\star-c) + d(p^\star) &= 0, \\
\displaystyle \alpha(1-d(p^\star)/C)(p^\star-c) + 1 &= 0, \\
\displaystyle \frac{\alpha e^{-\alpha(p^\star - p_0)}(p^\star - c) + 1+ e^{-\alpha(p^\star - p_0)}}{1+ e^{-\alpha(p^\star - p_0)}} &= 0, \\
\displaystyle \alpha(p^\star-c)+1]e^{-\alpha(p^\star - p_0)} + 1 &= 0.
\end{aligned}
$$

Since the last equation above does not have an analytical solution (at least we couldnâ€™t solve it), one can easily find the result with a newton-step algorithm or minimization problem. We will use the second approach with the following formulation:

$$
\displaystyle \min_{p \in \mathbb{R}} \big{(}[\alpha(p-c)+1]e^{-\alpha(p - p_0)} + 1\big{)}^2
$$

Example:

```{r logistic-regression-demand}
# Objective functions for optimization
demand_objective = function(par, p, d) sum((d - logistic(p, par[1], par[2], par[3]))^2)
price_objective = function(p, alpha, c, p0) (exp(-alpha*(p-p0))*(alpha*(p-c)+1) + 1)^2 
 
# A cleaner alternative for pricing optimization is to min:
price_objective2 = function(p, c, alpha, C, p0) -logistic(p, C, alpha, p0)*(p-c)
 
# synthetic data
p = seq(80,130)
c = 75
d = logistic(p, 120, -.15, 115) + rnorm(sd = 10, length(p))
profit = d*(p-c)
 
# Demand fitting, we can't use lm anymore
par.start = c(max(d), 0, mean(d)) # initial guess
 
demand_fit = optim(par = par.start, fn = demand_objective, method = 'BFGS',
                   p = p, d = d)
 
par = demand_fit$par # estimated parameters for demand function
demand.fitted = logistic(p, c = par[1], alpha = par[2], p0 = par[3])
profit.fitted = demand.fitted*(p - c)
 
# Pricing Optimization, we don't have a closed expression anymore
price_fit = optim(mean(p), price_objective, method = 'BFGS',
                  alpha = par[2], c = c, p0 = par[3])
 
# or
 
price_fit2 = optim(mean(p), price_objective2, method = 'BFGS',
                  c = c, C = par[1], alpha = par[2], p0 = par[3]) 
 
# both results are almost identical
p.max.profit = price_fit$par
 
# Graphics
df.logistic = data.frame('Prices' = p, 'Demand' = d, 'Demand.fitted' = demand.fitted,
                       'Profit.fitted' = profit.fitted, 'Profit' = profit)
 
ggplot(select(df.logistic, Prices, Demand)) + aes(x = Prices, y = Demand) +
  geom_point() +
  geom_line(data = df.logistic, aes(x = Prices, y = Demand.fitted), color = 'blue')

ggplot(select(df.logistic, Prices, Profit)) + 
  aes(x = Prices, y = Profit) +
  geom_point() + 
  geom_vline(xintercept = p.max.profit, lty = 2) +
  geom_line(data = df.logistic, aes(x = Prices, y = Profit.fitted), color = 'blue')
```

Since the optimal prices is a non-linear transformation of the demand parameters, the methodology above could lead to sub-optimal prices due to Jensenâ€™s inequality. Next post will address with examples how to estimate optimal prices when we have a lot of uncertainty in the demand function parameters.


# Fun with empirical and function-based derivatives in R ^[[Andrew Heiss](https://www.andrewheiss.com), 2018-02-15]

- For a more advanced topic on price optimization, refer to rmarkdown notebook by Andrew Heiss -- Chidi's budget utility [./chidi's_budget_utility.Rmd]

*tl;dr*: Use functions like `Deriv::Deriv()`, `splinefun()`, `approxfun()`, and `uniroot()` to do things with derivatives in R, both with actual functions and with existing empirical data

A typical microeconomics problem involves finding the optimal price and quantity of a product, given its demand and cost across different quantities. You can optimize this price and quantity and maximize profit by finding the point where the marginal cost and the marginal revenue (or the first derivatives of the cost and revenue functions) are equal to each other.

For instance, the demand for some product can be defined as $Q = 10 - 2P$ (where $Q =$ quantity and $P =$ price). The revenue you get from selling that product is defined as $R = PQ$ (just multiplying price Ã— quantity), so through some algebraic trickery and rearranging of Ps and Qs, you can create a revenue function for this demand curve: $R = 5Q - 0.5Q^2$. The cost function for this product can be defined as $C = 0.25Q + 0.5Q^2$.

To figure out the optimal profit, we set the marginal cost and marginal revenue equations equal to each other and solve for Q. Here, $\frac{dC}{dQ} = MC = 0.25 + 0.5Q$ and $\frac{dR}{dQ} = MR = 5 - Q$, so with algebra we can find the optimal point:

$$
\begin{aligned}
MC &= MR \\
0.25 + 0.5Q &= 5 - Q \\
1.5Q &= 4.75 \\
Q &= 3.1\overline{66}
\end{aligned}
$$

Phew. Calculus.

Doing this in R is fairly straightforward and far more flexible and far less algebra-intensive. First, define the functions:

```{r econ-functions, warning=FALSE, message=FALSE}
library(tidyverse)
library(Deriv)
library(pander)

demand <- function(q) 5 - (0.5 * q)
revenue <- function(q) (5 - 0.5 * q) * q

cost <- function(q) (0.25 * q) + (0.5 * q)^2
```

Plotting these functions is easy with `stat_function()`:

```{r plot-functions}
ggplot(mapping = aes(x = 0:10)) +
  stat_function(fun = cost, size = 1, aes(color = "Total cost")) +
  stat_function(fun = revenue, size = 1, aes(color = "Total revenue")) +
  labs(x = "Quantity", y = "Price") +
  scale_y_continuous(labels = scales::dollar) +
  scale_color_manual(values = c("Total cost" = "red", "Total revenue" = "blue"),
                     name = "Function") +
  theme_light() +
  theme(legend.position = "bottom")
```

Then, using `Deriv::Deriv()`, create derivative functions for the marginal cost and marginal revenue equations:

```{r econ-marginal-functions}
mr <- Deriv(revenue, "q")
mc <- Deriv(cost, "q")
```

We can also plot these:

```{r plot-marginal-functions}
ggplot(mapping = aes(x = 0:10)) +
  stat_function(fun = mc, size = 1, aes(color = "Marginal cost")) +
  stat_function(fun = mr, size = 1, aes(color = "Marginal revenue")) +
  labs(x = "Quantity", y = "Price") +
  scale_y_continuous(labels = scales::dollar) +
  scale_color_manual(values = c("Marginal cost" = "red", "Marginal revenue" = "blue"),
                     name = "Function") +
  coord_cartesian(ylim = c(0, 6)) +
  theme_light() +
  theme(legend.position = "bottom")
```

Finally, use the `uniroot()` function to look for the point where `mc` and `mr` intersect within a given range (here I'm looking between 1 and 10 since the demand curve goes negative after $Q =$ 10):

```{r opt-q}
optimal_q <- uniroot(function(x) mc(x) - mr(x), c(1, 10))
optimal_q$root
```

It's the same answer!

We can then plug `optimal_q$root` back into the marginal revenue and demand functions to find the optimal price (in a competitive market, the price should be equal to the marginal revenue, but this happens to be a monopoly, so the actual price is higher, but that's totally unrelated to the topic here):

```{r opt-p}
mr(optimal_q$root)
demand(optimal_q$root)
# oh noes monopolies
```

**However! Wait! Stop!** This is all well and fine if you have precise formulas for demand and cost. But real life is far messier than this. What if you don't know the underlying equations?

Often in economics, you have a set of quantities and prices based on empirical data. Market research and surveys can estimate the demand for a product, and tracking how fixed and variable costs change over time can estimate the costs for a product, but this data is all empirically based and not based in actual formulas. 

For instance, suppose you have this table of prices, quantities, and costs (which is actually really based on the demand and cost functions from earlier):

```{r empirical-data, results="asis"}
costs_revenues <- data_frame(Quantity = seq(0, 10, 1),
                             Price = demand(Quantity),
                             `Total Revenue` = revenue(Quantity),
                             `Total Cost` = cost(Quantity),
                             Profit = `Total Revenue` - `Total Cost`)

costs_revenues %>%
  mutate_at(vars(-Quantity), funs(scales::dollar(.))) %>%
  pandoc.table(style = "rmarkdown")
```

We can still use R to find the optimal quantity, ***even without actual formulas***. R has two base functions for approximating functions based on existing data. `approxfun()` will try to fit data linearly, and `splinefun()` will try to fit data with cubic splines (i.e. it can handle curvy lines better than `approxfun()`). 

First, we can plot the revenue and cost columns to see their shape:

```{r empirical-cost-revenue}
costs_revenues_plot <- costs_revenues %>% 
  select(Quantity, starts_with("Total")) %>% 
  gather(Variable, Price, -Quantity)

ggplot(costs_revenues_plot, aes(x = Quantity, y = Price, color = Variable)) +
  geom_line(size = 1) +
  scale_y_continuous(labels = scales::dollar) +
  scale_color_manual(values = c("red", "blue")) +
  theme_light() +
  theme(legend.position = "bottom")
```

Because both variables are curvilinear, it's probably best to approximate their functions using splines with `splinefun()`: 

```{r create-empirical-functions}
cost_empirical <- splinefun(x = costs_revenues$Quantity, 
                            y = costs_revenues$`Total Cost`)

revenue_empirical <- splinefun(x = costs_revenues$Quantity, 
                               y = costs_revenues$`Total Revenue`)
```

If we compare the empirically-based functions with their real-life counterparts, we can see that the approximation worked great:

```{r compare-functions}
cost(1:10)
cost_empirical(1:10)

revenue(1:10)
revenue_empirical(1:10)
```

Determining the marginal cost and revenue functions from these approximations is surprisingly easy because `splinefun()` objects have a built-in mechanism for returning derivatives with a `deriv` argument:

```{r compare-marginal-functions}
mc(1:10)
cost_empirical(1:10, deriv = 1)

mr(1:10)
revenue_empirical(1:10, deriv = 1)
```

Magic!

We can plot these empirically-approximated marginal functions and see that they intersect, as expected:

```{r plot-empirical-marginal-functions}
ggplot(mapping = aes(x = 0:10)) +
  stat_function(fun = cost_empirical, size = 1, args = list(deriv = 1),
                aes(color = "Marginal cost")) +
  stat_function(fun = revenue_empirical, size = 1, args = list(deriv = 1),
                aes(color = "Marginal revenue")) +
  labs(x = "Quantity", y = "Price") +
  scale_y_continuous(labels = scales::dollar) +
  scale_color_manual(values = c("Marginal cost" = "red", "Marginal revenue" = "blue"),
                     name = "Empirical function") +
  coord_cartesian(ylim = c(0, 6)) +
  theme_light() +
  theme(legend.position = "bottom")
```

Finally, we can use `uniroot()` to find where these two functions intersect:

```{r opt-q-empirical}
optimal_q_empirical <- uniroot(function(x) cost_empirical(x, deriv = 1) - 
                                 revenue_empirical(x, deriv = 1), c(1, 10))
optimal_q_empirical$root
```

It's the same!

And just like before, we can find the optimal price, given this quantity. But first we have to create an empirical function for the demand. The demand variable is linear here, so we can use `approxfun()`, but `splinefun()` works just fine too (and it has built-in derivative capabilities, while `approxfun()` doesn't).

```{r opt-p-empirical}
revenue_empirical(optimal_q_empirical$root, deriv = 1)

demand_empricial_spline <- splinefun(x = costs_revenues$Quantity,
                                     y = costs_revenues$Price)

demand_empricial_approx <- approxfun(x = costs_revenues$Quantity,
                                     y = costs_revenues$Price)

demand_empricial_spline(optimal_q_empirical$root)
demand_empricial_approx(optimal_q_empirical$root)
# oh noes monopolies again
```

We can plot all of these things together:

```{r plot-all-empirical}
ggplot(mapping = aes(x = 0:10)) +
  stat_function(fun = demand_empricial_spline, size = 1,
                aes(color = "Demand")) +
  stat_function(fun = cost_empirical, size = 1, args = list(deriv = 1),
                aes(color = "Marginal cost")) +
  stat_function(fun = revenue_empirical, size = 1, args = list(deriv = 1),
                aes(color = "Marginal revenue")) +
  geom_vline(xintercept = optimal_q_empirical$root, 
             color = "grey50", linetype = "dashed") +
  geom_hline(yintercept = revenue_empirical(optimal_q_empirical$root, deriv = 1), 
             color = "grey50", linetype = "dashed") +
  labs(x = "Quantity", y = "Price") +
  scale_y_continuous(labels = scales::dollar) +
  scale_color_manual(values = c("Marginal cost" = "red", "Marginal revenue" = "blue",
                                "Demand" = "darkgreen"),
                     name = "Function") +
  coord_cartesian(ylim = c(0, 6)) +
  theme_light() +
  theme(legend.position = "bottom")
```

In this case, the empirical solution and the function-based solution are identical, but that's only because I created the empirical data from the functions. In real life, though, this same process should work on any empirical price, quantity, and cost data.


# Price determination in monopoly market

``` {r}
library(Deriv)

# Demand and revenue stuff
# D: P = -0.09Q + 57.89
demand <- function(Q) -0.09 * Q + 57.89

# TR = PQ
revenue <- function(Q) Q * demand(Q)

# MR = TRâ€²
marginal_revenue <- Deriv(revenue, "Q")

# Total revenue given a prevailing market price of $25
revenue_price_taking <- function(Q) 25 * Q

# MR_price_taking = TR_price_takingâ€²
mr_price_taking <- Deriv(revenue_price_taking)


# Cost stuff
# TC: P = 0.07Q^2 + 3000
cost <- function(Q) 0.07 * Q^2 + 3000

# MC = TCâ€²
marginal_cost <- Deriv(cost, "Q")

# Average total cost: cost(Q) / Q
atc <- function(Q) cost(Q) / Q


# Figure out where all these functions cross
# Revenue maximization
max_revenue_q <- optimize(revenue, interval = c(100, 800), maximum = TRUE)$maximum
max_revenue <- revenue(max_revenue_q)

q_zero <- uniroot(revenue, c(400, 800))$root

# Profit maximization
max_profit_q <- uniroot(function(x) marginal_revenue(x) - 
                          marginal_cost(x), c(0, 600))$root
max_profit_p <- marginal_revenue(max_profit_q)
max_profit_p_demand <- demand(max_profit_q)

max_profit_q_price_taking <- uniroot(function(x) mr_price_taking(x) -
                                       marginal_cost(x), c(0, 600))$root
max_profit_p_price_taking <- mr_price_taking(max_profit_q_price_taking)

# Competitive equilibrium
competition_q <- uniroot(function(x) demand(x) - marginal_cost(x), c(0, 600))$root
competition_p <- demand(competition_q)


# Plot everything!
points_to_add <- tribble(
  ~x, ~y, ~label,
  max_profit_q, marginal_revenue(max_profit_q), "Maximum profit according to MR = MC",
  max_profit_q, demand(max_profit_q), "What theater will charge",
  competition_q, demand(competition_q), "Socially optimal level"
)

ggplot(mapping = aes(x = 1:q_zero)) +
  geom_hline(yintercept = 0, size = 0.25) +
  geom_vline(xintercept = 0, size = 0.25) +
  geom_segment(aes(x = max_profit_q, xend = max_profit_q,
                   y = 0, yend = demand(max_profit_q)),
               color = "grey50", linetype = "dashed", size = 0.5) +
  geom_segment(aes(x = 0, xend = max_profit_q,
                   y = demand(max_profit_q), yend = demand(max_profit_q)),
               color = "grey50", linetype = "dashed", size = 0.5) +
  geom_segment(aes(x = 0, xend = max_profit_q,
                   y = marginal_revenue(max_profit_q), yend = marginal_revenue(max_profit_q)),
               color = "grey50", linetype = "dashed", size = 0.5) +
  geom_segment(aes(x = competition_q, xend = competition_q,
                   y = 0, yend = demand(competition_q)),
               color = "grey50", linetype = "dashed", size = 0.5) +
  geom_segment(aes(x = 0, xend = competition_q,
                   y = demand(competition_q), yend = demand(competition_q)),
               color = "grey50", linetype = "dashed", size = 0.5) +
  stat_function(fun = marginal_revenue, size = 1.5, color = "blue") +
  stat_function(fun = marginal_cost, size = 1.5, color = "red") +
  stat_function(fun = demand, size = 1.5, color = "darkblue") + 
  stat_function(fun = atc, size = 0.5, color = "orange") +
  geom_point(data = points_to_add, aes(x = x, y = y), size = 2) +
  annotate(geom = "label", x = 600, y = demand(600), label = "D",
           size = 3, fill = "darkblue", color = "white") +
  annotate(geom = "label", x = 400, y = marginal_cost(400), label = "MC",
           size = 3, fill = "red", color = "white") +
  annotate(geom = "label", x = 300, y = marginal_revenue(300), label = "MR",
           size = 3, fill = "blue", color = "white") +
  annotate(geom = "label", x = 600, y = atc(600), label = "ATC",
           size = 3, fill = "orange", color = "white") +
  geom_label(data = points_to_add, aes(x = x, y = y, label = label), 
             size = 3, hjust = -0.1) +
  scale_y_continuous(labels = dollar) +
  coord_cartesian(ylim = c(-10, 60)) +
  labs(x = "Tickets (Q)", y = "Price (P)") +
  theme_minimal(9) +
  theme(panel.grid = element_blank())
```


# Notable formula and graphs

## Formula

- Demand:

$$
P = aQ + b
$$

- Total cost:

$$
\begin{aligned}
TC &= TFC + TVC \\
&\text{or} \\
\text{A formula using } & Q \text{, like} \\
TC &= aQ^2 + b
\end{aligned}
$$

##

- Average cost:

$$
AC = \frac{TC}{Q}
$$

- Marginal cost:

$$
\begin{aligned}
  MC &= \frac{\Delta TC}{\Delta Q} \\
  &\text{or} \\
  MC &= \text{First derivative of TC} \\
  &= 2aQ \text{ (if } TC = aQ^2 + b)
\end{aligned}
$$

##

- Total revenue:

$$
\begin{aligned}
  TR &= PQ \\
  &\text{or} \\
  TR &= (aQ + b)Q \\
  &= aQ^2 + bQ
\end{aligned}
$$

- Average revenue:

$$
AR = \frac{TR}{Q}
$$

##

- Marginal revenue:

$$
\begin{aligned}
  MR &= \frac{\Delta TR}{\Delta Q} \\
  &\text{or} \\
  MR &= \text{First derivative of TR} \\
  &= 2aQ + b \text{ (if } TR = aQ^2 + bQ)
\end{aligned}
$$

- Maximum profit:

$$
max(\pi): MC = MR
$$

##

- Price elasticity of demand = $- \frac{\Delta Q}{\Delta P} \times \frac{P}{Q}$):

$$
\varepsilon = -\frac{\% \text{ change in quantity demand}}{\% \text{ change in price}} = - \frac{\Delta Q}{\Delta P} \times \frac{P}{Q}
$$


## Tax graph

- Consumer surplus, producer surplus, tax revenues, tax burdens, and deadweight loss (use algebra and geometry to figure out the areas of the triangles ($\frac{1}{2} \times b \times h$) and rectangles ($l \times w$)):

```{r supply-demand-surplus, warning=FALSE, message=FALSE, fig.width=5, fig.height=4, fig.cap="Supply and demand surplus and taxation scheme", echo=FALSE, eval=TRUE, out.width="50%", fig.align='center'}
# source graphics.R and supply-demand-surplus.R
tax_graph(demand, supply, supply_tax, NULL, TRUE)
```

## Maria's best response curve

```{r labor-discipline-stuff, echo=FALSE, fig.width=6, fig.height=5, fig.cap="Indifference curves", echo=FALSE, eval=TRUE, out.width="60%", fig.align='center'}
library(Deriv)
library(ineq)
library(scales)

# Formula for polynomial curve: 60x^4 + 5x + 6
#
# I invented this by using WolframAlpha to fit a polynomial linear model that
# when through a set of specific points using this command (with a maximum
# exponent of 4):
#
# LinearModelFit[{{0, 6}, {0.5, 12}, {-0.8, 24}, {-0.9, 48}}, {1, x, x^4}, x]
#
# It yielded a messy model with like 78.3x^4, 10.1x + 3.44, so I put that in
# Desmos.com, moved the y intercept to 6, and tinkered with the other coefficients
# until it looked okay. Finally, I switched x and y so it's horizontal
response_curve <- function(y) 60*y^4 + 5*y + 6
response_deriv <- Deriv(response_curve)

# We can use these functions to find the x value (wage) that corresponds with a
# given y value (level of effort)
# response_curve(0.5)

# We can also find the slope of the response curve at that point:
# response_deriv(0.5)

# Armed with a slope an a single point (here slope = 35, point = (12.25, 0.5)),
# we can create a formula for the line that is tangent to the response curve at
# that point.
#
# Formula for y-intercept give a slope and a single point
# y - y1 = m(x = x1)
#
# Because we've flipped the curve sidways and switched x and y, we need to
# rearrange this in terms of x:
#
# x = (y - y1) / m + x1
#
tangent_intercept <- function(x, m, x1, y1) (x - x1) / m + y1

# Here we invert tangent_intercept() by dividing by the negative derivative
# It's negative because 1/y is really y^-1
flipped_intercept <- function(x, effort) {
  # m needs to be inverted because of switched x/y thing, so it's 1/deriv
  tangent_intercept(x, m = 1 / response_deriv(effort), 
                    x1 = effort, y1 = response_curve(effort)) / 
    -response_deriv(effort)
}

# Create a line based on the slope and intercept of the flipped derivative
tangent_line <- function(x, effort) {
  (1 / response_deriv(effort) * x) + flipped_intercept(0, effort)
}

isocost_line <- function(x, m, b) m * x + b

# FINALLY we can plot the flipped polynomial curve. This should, in theory, be
# as simple as rearranging our x = 60y^4 + 5y + 6 formula to be in terms of y
# and then using stat_function() to plot it, BUT polynomials are demonic beasts
# and doing this is beyond my abilities.
#
# GO HERE and see what I mean: 
# https://www.wolframalpha.com/input/?i=x+%3D+60y%5E4+%2B+5y+%2B+6+in+terms+of+y
#
# So to cheat, we make a little data frame with a range of x and y values and
# then plot that with geom_line()
flipped_curve <- tibble(y = seq(0, 1, 0.01)) %>% 
  mutate(x = response_curve(y))

# Finally, we can plot all these things!
ggplot(data = tibble(x = 0:50), aes(x = x)) + 
  # Add flipped polynomial curve
  geom_line(data = flipped_curve, aes(x = x, y = y), 
            size = 1, color = nord_dk_blue) +
  # Mark tangent point
  annotate(geom = "segment", x = response_curve(0.5), y = 0, 
           xend = response_curve(0.5), yend = 0.5,
           linetype = "dashed", color = "grey50", size = 0.5) +
  annotate(geom = "segment", x = 0, y = 0.5, 
           xend = response_curve(0.5), yend = 0.5,
           linetype = "dashed", color = "grey50", size = 0.5) +
  # Add tangent lines
  # If I wanted to be super fancy, I could figure out the width of the base of
  # the triangle formed by each tangent line so that I could get Â± the same x
  # distance to the left and right of each point and have each tangent segment
  # use the same horizontal distance, but that sounds too hard, so I just picked
  # numbers until it looked okay
  stat_function(fun = tangent_line, args = list(effort = 0.5),
                color = nord_red, size = 1, 
                xlim = c(response_curve(0.5) - 10, response_curve(0.5) + 10)) +
  stat_function(fun = isocost_line, args = list(m = 1/80, b = 0.15),
                color = nord_orange, size = 1,
                xlim = c(response_curve(0.5) - 10, response_curve(0.5) + 10)) + 
  stat_function(fun = isocost_line, args = list(m = 1/20, b = 0.15),
                color = nord_yellow, size = 1,
                xlim = c(response_curve(0.5) - 10, response_curve(0.5) + 10)) + 
  # annotate(geom = "label", x = tangent_line(5, 0.5), y = 0.5)
  annotate(geom = "label", x = 15, y = isocost_line(15, m = 1/20, b = 0.15), 
           label = "A", fill = nord_yellow, color = "white", size = pts(12)) +
  annotate(geom = "label", x = 17.5, y = tangent_line(17.5, effort = 0.5), 
           label = "B", fill = nord_red, color = "white", size = pts(12)) +
  annotate(geom = "label", x = 20, y = isocost_line(20, m = 1/80, b = 0.15), 
           label = "C", fill = nord_orange, color = "white", size = pts(12)) +
  annotate(geom = "point", x = response_curve(0.5), y = 0.5, size = 2) +
  annotate(geom = "text", x = response_curve(0.5), y = 0.5, 
           hjust = -0.1, vjust = 1.1, size = pts(10),
           label = paste0("(", dollar(response_curve(0.5)), ", ", 
                          percent_format(accuracy = 1)(0.5), ")")) +
  annotate(geom = "text", x = 6, y = 0, hjust = 1, vjust = -1,
           label = "$6 reservation wage", size = pts(10)) +
  # Labels and scale stuff
  labs(x = "Wage per hour", y = "Work effort from employee",
       title = "Maria's best response curve and employer isocost lines") +
  scale_x_continuous(labels = dollar, expand = c(0, 0.3)) +
  scale_y_continuous(labels = percent_format(accuracy = 1), expand = c(0, 0)) +
  coord_cartesian(xlim = c(0, 25), ylim = c(0, 1)) +
  # theme_econ(base_size = 13, axis_line = TRUE) +
  theme_bw() +
  theme(panel.grid = element_blank(),
        plot.title = element_text(size = rel(1.1), hjust = 0.5))
```

##

Would any of the following affect Mariaâ€™s best response curve or the firm's isocost lines for effort in the figure above? If so, explain how?

1. The government decides to increase childcare subsidies for working parents but not for those unemployed. Assume Maria has a child and is eligible for the subsidy.
2. Demand for the firm's output rises as celebrities endorse the good.
3. Improved technology makes Maria's job easier.

# Pricing optimization: How to find the price that maximizes your profit

One of the major problems in finance/economics is: As manager of a company/store, how much should I *charge* in order to maximize my revenue or profit?

Obviously, the answer isnâ€™t "as high as possible". If you charge one hundred dollars for a candy, probably only one or two people will accept to buy it. Although the profit per product is very high, you probably wonâ€™t even your fixed costs. Charge a very small is also not the best call.

Before showing an example for this problem, let us build some simple formulas.

Imagine a monopolist selling a specific product with demand curve $\displaystyle Q(p)$, where $\displaystyle Q(p)$ is the quantity sold given a specific price $p$. To simplify things, let's suppose that $Q(p)$ is a linear functions:

$$
\displaystyle Q(p) = \alpha p + \beta
$$

The total revenue will be given by:

$$
\displaystyle Q(p) = pQ(p) = \alpha p^2 + p\beta
$$

And total profit will be given by:

$$
\displaystyle L(p) = (p-c)Q(p) = \alpha p^2 - \alpha pc + \beta (p-c)
$$

Where $c$ is the unity cost of the product. Adding fixed costs in the profit equation does not change the price police, so we will suppose it zero.

Next, we differentiate the equations for $\displaystyle R(p)$ and $\displaystyle L(p)$ to find the first order conditions, which allow us to find the optimal police under the hypothesis of a linear demand curve. $\alpha$ is expected to be negative (demand decrease when price increase) $R$ and $L$ are concave functions of $p$. As consequence, the critical point will be a maximum point. Therefore, the optimal police for revenue is given by:

$$
\displaystyle P_{\textrm{max rev}} = \frac{-\beta}{2\alpha}
$$

And for profit:

$$
\displaystyle P_{\textrm{max prof}} = \frac{-\beta + \alpha c}{2\alpha}
$$

Note that sometimes people write the linear demand curve as $\displaystyle Q(p) = -\alpha p + \beta$, in this case $\alpha$ should be positive, and the signs in equation 2 and equation 3 must change. Moreover, it is interesting to note that the price that maximizes profit is always bigger than the one that maximizes total revenue because $c$ is always positive.

If taxes are calculated just on profit the price police remains the same. However, countries like Brazil usually charges a lot of taxes on total revenue. In this case, the price police for maximizing revenue doesnâ€™t change, but the police for maximizing profit will change according to the following expression:

$$
\displaystyle P_{\textrm{max prof}}^{(tax)} = \frac{-\beta(1-tax) + \alpha c}{2\alpha(1-tax)}
$$

## Example and implementations

As an example of how to proceed with the estimation of the optimum price, letâ€™s generate a linear demand curve for daily selling of a product:

```{r demand-implementation, cache=TRUE}
# example of linear demand curve (first equation)

demand <- function(p, alpha = -40, beta = 500, sd = 10) {
  error = rnorm(length(p), sd = sd)
  q = p*alpha + beta + error
 
  return(q)
}

set.seed(100)
 
prices <- seq(from = 5, to = 10, by = 0.1)
q <- demand(prices)
 
data = data.frame('prices' = prices,'quantity' = q)
 
ggplot(data, aes(prices, quantity)) +
  geom_point(shape=1) +
  geom_smooth(method='lm') +
  ggtitle('Demand Curve')

```

Imagine a company that has been selling the product which follows the demand curve above for a while (one year changing prices daily), testing some prices over time. The following time-series is what we should expect for the historical revenue, profit and cost of the company:

```{r price-time-profile, cache=TRUE}
set.seed(10)
 
hist.prices = rnorm(252, mean = 6, sd = .5) # random prices defined by the company
hist.demand = demand(hist.prices) # demand curve defined in the chunck above
hist.revenue = hist.prices*hist.demand # From the revenue equation
unity.cost = 4 # production cost per unity
hist.cost = unity.cost*hist.demand
hist.profit = (hist.prices - unity.cost)*hist.demand # From the price equation
 
data = data.frame('Period' = seq(1,252),'Daily.Prices' = hist.prices,
                  'Daily.Demand' = hist.demand, 'Daily.Revenue' = hist.revenue,
                  'Daily.Cost' = hist.cost, 'Daily.Profit' = hist.profit)
 
ggplot(data, aes(Period, Daily.Prices)) +
  geom_line(color = 4) +
  ggtitle('Historical Prices used for explotation')

ggplot(data, aes(Period, Daily.Revenue, colour = 'Revenue')) +
  geom_line() +
  geom_line(aes(Period, Daily.Profit, colour = 'Profit')) +
  geom_line(aes(Period, Daily.Cost, colour = 'Cost')) +
  labs(title = 'Historical Performance', colour = '')
```

We can recover the demand curve using the historical data (that is how it is done in the real world).

```{r model-params, results="asis", echo=FALSE, cache=TRUE}
model.fit <- lm(hist.demand ~ hist.prices) # linear model for demand
stargazer::stargazer(model.fit, type = 'latex', header = FALSE, 
                     title = "Regression of historical prices with historical demand for the commodity", style = "all") # output
```

And now we need to apply equation 2 and equation 3.

```{r estimated-params, cache=TRUE}
# estimated parameters
beta = model.fit$coefficients[1]
alpha = model.fit$coefficients[2]  
 
p.revenue = -beta/(2*alpha) # estimated price for revenue
p.profit = (alpha*unity.cost - beta)/(2*alpha) # estimated price for profit
```

The final plot with the estimated prices:

```{r graph-estimated-demand, cache=TRUE}
true.revenue = function(p) p*(-40*p + 500) # Revenue with true parameters (chunck demand)
true.profit = function(p) (p - unity.cost)*(-40*p + 500) # price with true parameters
 
# estimated curves
estimated.revenue = function(p) p*(model.fit$coefficients[2]*p + model.fit$coefficients[1])
estimated.profit = function(p) (p - unity.cost)*(model.fit$coefficients[2]*p + model.fit$coefficients[1])
 
opt.revenue = true.revenue(p.revenue) # Revenue with estimated optimum price
opt.profit = true.profit(p.profit) # Profit with estimated optimum price
 
# plot
df = data.frame(x1 = p.revenue, x2 = p.profit,
                y1 = opt.revenue, y2 = opt.profit, y3 = 0)
 
ggplot(data = data.frame(Price = 0)) +
  stat_function(fun = true.revenue, mapping = aes(x = Price, color = 'True Revenue')) +
  stat_function(fun = true.profit, mapping = aes(x = Price, color = 'True Profit')) +
  stat_function(fun = estimated.revenue, mapping = aes(x = Price, color = 'Estimated Revenue')) +
  stat_function(fun = estimated.profit, mapping = aes(x = Price, color = 'Estimated Profit')) +
  scale_x_continuous(limits = c(4, 11)) +
  labs(title = 'True curves without noise') +
  ylab('Results') +
  scale_color_manual(name = "", values = c("True Revenue" = 2, "True Profit" = 3, "Estimated Revenue" = 4, "Estimated Profit" = 6)) +
  geom_segment(aes(x = x1, y = y1, xend = x1, yend = y3), data = df) +
  geom_segment(aes(x = x2, y = y2, xend = x2, yend = y3), data = df)
```

Final observations

As you can see, the estimated Revenue and estimated Profit curves are quite similar to the true ones without noise and the expected revenue for our estimated optimal policies looks very promising. Although the linear and monopolist assumption looks quite restrictive, this might not be the case, check @besbes2015surprising and @cooper2015learning.

Due to Jensenâ€™s inequality, if one expect a large variance for $\alpha$, it might be useful to calculate the optimal price simulating $\alpha$, $\beta$.

See also: @talluri2006theory, @phillips2005pricing.

# Consumer and producer surplus

Let's first define supply and demand functions.

$$
\begin{aligned}
p_{\textrm{demand}} &= (q-10)^2 \\
p_{\textrm{supply}} &= q^2 + 2q + 8
\end{aligned}
$$

```{r supply-demand-funs, cache=TRUE}
demand <- function(q)(q - 10)^2
supply <- function(q) q^2 + 2*q + 8
```

We plot these functions over a specified domain.

```{r fun-domain-plotting, cache=TRUE}
x <- 2:8

fun_domain_gg <- ggplot() +
  stat_function(aes(x, color = "Demand"), fun = demand) +
  stat_function(aes(x, color = "Supply"), fun = supply)

fun_domain_gg
```


To find the equilibrium point, or, the point of intesection, `uniroot` function could be used. This requires an anonymous function to be passes that calculates the difference between the supply and demand. Uniroot function then finds where this difference is zero. This gives us the equilibrium quanity _q*_. Passing this quantity to the supply function then gives us the equilibrium price _p*_.

```{r eq-quant-price, cache=TRUE}
# eq quantity
q <- uniroot(function(x)demand(x)-supply(x), range(x))
q <- q$root # saved as root object

# eq price
p <- supply(q) # or demand/both have same result

# annotating the point (q, p) on the chart
fun_domain_gg <- fun_domain_gg +
  annotate("point", x = q, y = p, color = "grey4")

fun_domain_gg
```

Adding some dashed segments from the equilibrium point to the axes, we get following chart.

```{r segment-to-axes, cache=TRUE}
fun_domain_gg <- fun_domain_gg +
  annotate("segment", x = q, xend = q, y = 0, yend = p, 
           linetype = "dashed", color = "grey30") +
  annotate("segment", x = 0, xend = q, y = p, yend = p,
           linetype = "dashed", color = "grey30")

fun_domain_gg
```


For shading the area between demand curve and the dashed line segment (consumer surplus), and the area below the dashed line above supply curve (producer surplus), we need to pre-calculate a dummy series from 0 to the equilibrium point, which will be passed to the `geom_ribbon` function.

```{r ribboning-plot, cache=TRUE}
z <- seq(0, q, 0.01)

fun_domain_gg <- fun_domain_gg +
  geom_ribbon(aes(x = z, ymin = supply(z), ymax = p,
                  fill = "Producer surplus"), alpha = 0.25) +
  geom_ribbon(aes(x = z, ymin = p, ymax = demand(z),
                  fill = "Consumer surplus"), alpha = 0.25)

# beautifying
fun_domain_gg +
  scale_x_continuous(expand = c(0,0),
                     breaks = q, labels = "q*") + 
  scale_y_continuous(expand = c(0,0), 
                     breaks = p, labels = "p*") +
  theme_minimal() +
  theme(panel.grid = element_blank(),
        legend.position = c(1,1),
        legend.justification = c(1,1),
        legend.spacing = unit(0, "cm"),
        legend.margin = margin(0, 0, 0, 0, "cm")) +
  labs(x = "Quantity", y = "Price",
       color = NULL, fill = NULL)
```

Numerical values for the surpluses can be obtained from following relation

$$
\begin{aligned}
\textrm{consumer surplus} &= \int^{q^*}_0 D(x)dx - p^*q^* \\
\textrm{producer surplus} &= p^*q^*- \int^{q^*}_0 S(x)dx
\end{aligned}
$$

In R, we compute the values by defining a function.

```{r consumer-producer-fun}
surpluss <- function(demand, supply, domain){
  q <- uniroot(function(x)demand(x)-supply(x), domain)$root
  p <- supply(q)
  
  consumer_surplus <- integrate(demand, 0, q)$value - p*q
  producer_surplus <- p*q - integrate(supply, 0, q)$value
  list("consumer_surplus" = consumer_surplus,
       "producer_surplus" = producer_surplus)
}

surpluss(demand, supply, c(2, 8)) %>% 
  enframe() %>% 
  unnest() %>% 
  knitr::kable(booktabs = TRUE)
```


# Curve intersect function^[https://github.com/andrewheiss/reconPlots]

The author of `reconPlots` package has defined a function which helps obtain a point or set of points that are useful for working with straight lines or bezier. Here's an illustration for that.

To obtain intersection of lines using dataframe and then use them further,

```{r line-intersect, cache=TRUE}
line1 <- data.frame(x = c(1, 9), y = c(1, 9))
line2 <- data.frame(x = c(9, 1), y = c(1, 9))

# intersection of lines
line_intersection <- curve_intersect(line1, line2)

# plotting
ggplot(mapping = aes(x = x, y = y)) +
  geom_line(data = line1, color = "red", size = 1) +
  geom_line(data = line2, color = "blue", size = 1) +
  geom_vline(xintercept = line_intersection$x, linetype = "dotted") +
  geom_hline(yintercept = line_intersection$y, linetype = "dotted") +
  theme_classic()
```

For working with curved bezier and its dataframe,

```{r curved-bezier, cache=TRUE}
curve1 <- data.frame(Hmisc::bezier(c(1, 8, 9), c(1, 5, 9)))
curve2 <- data.frame(Hmisc::bezier(c(1, 3, 9), c(9, 3, 1)))

# demand curve
ggplot(mapping = aes(x = x, y = y)) + 
  geom_path(data = curve2, color = "#FF4036", size = 1) +
  theme_classic() + 
  labs(x = "Quantity", y = "Price") +
  coord_equal() +
  ggtitle(label = "Demand curve")

# supply curve
ggplot(mapping = aes(x = x, y = y)) + 
  geom_path(data = curve1, color = "#0073D9", size = 1) +
  theme_classic() + 
  labs(x = "Quantity", y = "Price") +
  coord_equal() +
  ggtitle(label = "Supply curve")

# Simple intersection approximation
fun_supply <- approxfun(curve1$x, curve1$y, rule = 2)
fun_demand <- approxfun(curve2$x, curve2$y, rule = 2)

intersection_funs <-  uniroot(function(x) fun_supply(x) - fun_demand(x), range(curve2$x))
intersection_funs

ggplot(mapping = aes(x = x, y = y)) + 
  geom_path(data = curve1, color = "#0073D9", size = 1) + 
  geom_path(data = curve2, color = "#FF4036", size = 1) + 
  geom_vline(xintercept = intersection_funs$root, linetype = "dotted") +
  theme_classic() + 
  coord_equal()

# use of intersection function
curve_intersection <- curve_intersect(curve1, curve2)
ggplot(mapping = aes(x = x, y = y)) +
  geom_line(data = curve1, color = "red", size = 1) +
  geom_line(data = curve2, color = "blue", size = 1) +
  geom_vline(xintercept = curve_intersection$x, linetype = "dotted") +
  geom_hline(yintercept = curve_intersection$y, linetype = "dotted") +
  theme_classic()
```

Curves can also be defined with functions, with argument `emirical = FALSE` in the `curve_intersect()`. For example;

```{r function-curve, cache=TRUE}
curve1 <- function(p) (p + 2)^2
curve2 <- function(p) p^2 + 3*p + 5 
x_range <- 0:8

curve_intersection <- curve_intersect(curve1, curve2, empirical = FALSE, 
                                      domain = c(min(x_range), max(x_range)))

ggplot() +
  stat_function(aes(x_range), color = "blue", size = 1, fun = curve1) +
  stat_function(aes(x_range), color = "red", size = 1, fun = curve2) +
  geom_vline(xintercept = curve_intersection$x, linetype = "dotted") +
  geom_hline(yintercept = curve_intersection$y, linetype = "dotted") +
  theme_classic()
```

# Cobb douglas model

## Cobb douglas type 1 production function with n inputs/goods

$I$ = Vector of inputs
$elasticity$ = Vector of elasticities, must be the same length as $I$. Defaults to equal elasticities for all inputs with sum of those equal to 1.
$K$ = Model constant. Defaults to 1

```{r cd1}
require(Recon)
I <- c(3, 4, 5)
elasticity <- rep(1/length(I), times = length(I))
K <- 1

Q <- I * elasticity
S <- prod(Q)
y <- K * S
CD <- list(y = y, Degree = sum(elasticity))

# cobb douglas function:
CD

cobb_douglas(I)
```

## Cobb douglas type 2 production function with two inputs/goods

$x$ = data frame with two columns
$tfp$ = Model constant
$\alpha$ = first input's elasticity. Defaults to random number between 0 and 1, rounded to two digits.
$\beta$ = second input's elasticity. Defaults to $1-\alpha$

```{r cd2}
input1 <- c(3, 4, 5)
input2 <- c(1, 5, 6)
df <- tibble(input1, input2)
alpha <- 0.4
beta <- 1-alpha
tfp <- 1

y <- vector()
for (i in 1:nrow(df)) {
  y[i] <- tfp * df[i, 1]^alpha * df[i, 2]^beta
}
y

cobb_douglas_2(df, TFP = 1, alpha = 0.4, beta = 1-0.4)
```


# Bibliography

## For more information
